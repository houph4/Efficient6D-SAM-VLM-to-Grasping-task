A SAM-VLM based script that can be used for actual grasping, which can output the position information of the 3DBBOX of the final grabbing object and its minimum bounding box narrow edge angle posture, and output the narrow edge width for gripper opening control.
You can try it through Azure_Kinect camera and with our LightPose (or your own network). Please correctly configure the [ultratics](https://github.com/ultralytics) environment, [openai-python](https://github.com/openai/openai-python) environment and [Azure Kinect SDK](https://github.com/microsoft/Azure-Kinect-Sensor-SDK). We will release a detailed version of the environment in our computer.
